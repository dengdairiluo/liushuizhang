# Spark快速大数据分析

## 1 Spark数据分析导论

### 1.1 Spark是什么

### 1.2 一个大一统的软件栈

#### 1.2.1 Spark Core

#### 1.2.2 Spark SQL

#### 1.2.3 Spark Streaming

#### 1.2.4 MLlib

#### 1.2.5 GraphX

#### 1.2.6 集群管理器

### 1.3 Spark的用户和用途

#### 1.3.1 数据科学任务

#### 1.3.2 数据处理应用

### 1.4 Spark简史

### 1.5 Spark的版本和发布

### 1.6 Spark的存储层次

## 2 Spark下载与入门

### 2.1 下载Spark

### 2.2 SPark中python和Scala的shell

### 2.3 Spark核心概念简介

### 2.4 独立应用

#### 2.4.1 初始化SparkContext

#### 2.4.2 构建独立应用

### 2.5 总结

## 3 RDD编程

### 3.1 RDD基础

### 3.2 创建RDD

### 3.3 RDD操作

#### 3.3.1 转化操作

#### 3.3.2 行动操作

#### 3.3.3 惰性求值

### 3.4 向Spark传递函数

#### 3.4.1 Python

#### 3.4.2 Scala

#### 3.4.3 Java

### 3.5 常见的转化操作和行动操作

#### 3.5.1 基本的RDD

#### 3.5.2 在不同RDD类型间转换

### 3.6 持久化(缓存)

### 3.7 总结

## 4 键值对操作

### 4.1 动机

### 4.2 创建Pair RDD

### 4.3 Pair RDD的转化操作

#### 4.3.1 聚合操作

#### 4.3.2 数据分组

#### 4.3.3 连接

#### 4.3.4 数据排序

### 4.4 Pair RDD的行动操作

### 4.5 数据分区(进阶)

#### 4.5.1 获取RDD分区方式

#### 4.5.2 从分区中获益的操作

#### 4.5.3 影响分区方式的操作

#### 4.5.4 示例：PageRank

#### 4.5.5 自定义分区的方式
